<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222"/>


  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css"/>



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link rel="stylesheet" href="/lib/pace/pace-theme-center-atom.min.css?v=1.0.2"/>























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2"/>

<link rel="stylesheet" href="/css/main.css?v=6.7.0"/>


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/header-32x32-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/header-16x16-next.png?v=6.7.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.7.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.7.0',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="《Normalizing Flows for Probabilistic Modeling and Inference》论文笔记标准化流能做什么？假设我们想生成人脸，但我们并不知道人脸图片在高维空间D的分布，我可以用一个简单的分布pz，从中sample出一个向量z，让它通过标准化流$G$，得到一个新的向量x，让x的分布与人脸的分布相近，这样我们就可以生成任意张不同的人脸照片。 再举一个例子，如果我">
<meta property="og:type" content="article">
<meta property="og:title" content="标准化流(上)">
<meta property="og:url" content="https:&#x2F;&#x2F;tianhongzxy.github.io&#x2F;2020&#x2F;07&#x2F;29&#x2F;%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%81(%E4%B8%8A)&#x2F;index.html">
<meta property="og:site_name" content="TianHongZXY">
<meta property="og:description" content="《Normalizing Flows for Probabilistic Modeling and Inference》论文笔记标准化流能做什么？假设我们想生成人脸，但我们并不知道人脸图片在高维空间D的分布，我可以用一个简单的分布pz，从中sample出一个向量z，让它通过标准化流$G$，得到一个新的向量x，让x的分布与人脸的分布相近，这样我们就可以生成任意张不同的人脸照片。 再举一个例子，如果我">
<meta property="og:locale" content="en">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;007S8ZIlgy1gh83q2id4wj31440rn7pg.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;007S8ZIlgy1gh6ofqbf82j30dw0bngln.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;007S8ZIlgy1gh83uwvxr1j30cf0byt8p.jpg">
<meta property="og:updated_time" content="2020-07-30T07:14:47.423Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;007S8ZIlgy1gh83q2id4wj31440rn7pg.jpg">






  <link rel="canonical" href="https://TianHongZXY.github.io/2020/07/29/标准化流(上)/"/>



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>标准化流(上) | TianHongZXY</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">TianHongZXY</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">那时我们一无所有，也没有什么能妨碍我们享受静夜</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br/>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br/>About</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br/>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br/>Archives</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://TianHongZXY.github.io/2020/07/29/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%81(%E4%B8%8A)/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TianHongZXY"/>
      <meta itemprop="description" content="浪漫骑士 行吟诗人 自由思想者"/>
      <meta itemprop="image" content="/images/header.jpg"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TianHongZXY"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">标准化流(上)

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2020-07-29 14:43:37" itemprop="dateCreated datePublished" datetime="2020-07-29T14:43:37+08:00">2020-07-29</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-07-30 15:14:47" itemprop="dateModified" datetime="2020-07-30T15:14:47+08:00">2020-07-30</time>
              
            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/07/29/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%81(%E4%B8%8A)/#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">Comments: </span> <span class="post-comments-count valine-comment-count" data-xid="/2020/07/29/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%81(%E4%B8%8A)/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="《Normalizing-Flows-for-Probabilistic-Modeling-and-Inference》论文笔记"><a href="#《Normalizing-Flows-for-Probabilistic-Modeling-and-Inference》论文笔记" class="headerlink" title="《Normalizing Flows for Probabilistic Modeling and Inference》论文笔记"></a>《Normalizing Flows for Probabilistic Modeling and Inference》论文笔记</h1><p>标准化流能做什么？假设我们想生成人脸，但我们并不知道人脸图片在高维空间D的分布，我可以用一个简单的分布pz，从中sample出一个向量z，让它通过标准化流$G$，得到一个新的向量x，让x的分布与人脸的分布相近，这样我们就可以生成任意张不同的人脸照片。</p>
<p>再举一个例子，如果我们有一堆冷漠脸的图片，和一堆笑脸的图片，把多张冷漠脸通过逆标准化流$G^{-1}$，取平均得到一个向量z1，再把多张笑脸通过逆标准化流$G^{-1}$，取平均得到向量z2，用z2减去z1得到z3，z3应该就是在z空间中，从冷漠脸区域指向笑脸区域的向量，那我们现在把任意一个冷漠脸的人的图片x拿来通过逆标准化流$F^{-1}$得到z4，令z5 = z3 + z4，再通过标准化流$F$应该就可以得到这个人笑脸样子的图片了！</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh83q2id4wj31440rn7pg.jpg" alt="标准化流变笑脸"></p>
<p>李宏毅老师说flow-based model虽然效果不错，但是没有VAE和GAN有名的原因可能是因为它的数学太多，导致用的人不多hhh</p>
<h1 id="1-前置知识"><a href="#1-前置知识" class="headerlink" title="1. 前置知识"></a>1. 前置知识</h1><p>标准化流(Normalizing Flow)能够将简单的概率分布转换为极其复杂的概率分布，可以用在生成式模型、强化学习、变分推断等领域，构建它所需要的工具是：行列式(Determinant)、雅可比矩阵(Jacobi)、变量替换定理(Change of Variable Theorem)，下面先简单介绍这三个工具。</p>
<h2 id="1-1-行列式"><a href="#1-1-行列式" class="headerlink" title="1.1 行列式"></a>1.1 行列式</h2><p>行列式的求法不再赘述，我们主要需要理解的是行列式的物理意义。一个矩阵的行列式的值表示的是该矩阵对空间所做的变换，将原来的空间放大或缩小了多少倍，比如二维空间在原点有一个边长为1的正方形a，对它做变换得到新的正方形b，$b = Wa$，$W=\left[\begin{matrix} 2 &amp; 0 \ 0 &amp; 2\end{matrix}\right]$，新的正方形边长被放大为原来的2倍，面积为原来的4倍，$det(W) = 4$，</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6ofqbf82j30dw0bngln.jpg" style="zoom:50%;" align="left" />                                     <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh83uwvxr1j30cf0byt8p.jpg" alt="image-20200728143736053" style="zoom:50%;" align="right" /></p>
<p>​                              $a \Longrightarrow b = Wa$</p>
<p>三维以及更高维空间亦同理</p>
<h2 id="1-2-雅可比矩阵"><a href="#1-2-雅可比矩阵" class="headerlink" title="1.2 雅可比矩阵"></a>1.2 雅可比矩阵</h2><p>设有一个二维向量$z=\left[\begin{matrix} z_{1} \ z_{2} \end{matrix}\right]$，给定变换$f$，$x=f(z)=\left[\begin{matrix} z_{1}+z_{2} \ 2z_{1}\end{matrix}\right]$，那么变换$f$的雅可比矩阵$J_{f}$</p>
<script type="math/tex; mode=display">
J_{f}=\left[\begin{array}{ccc}
\frac{\partial x_{1}}{\partial z_{1}} & \frac{\partial x_{1}}{\partial z_{2}} \\
\frac{\partial x_{2}}{\partial z_{1}} & \frac{\partial x_{2}}{\partial z_{2}}
\end{array}\right]
=\left[\begin{array}{ccc}
1 & 1 \\
2 & 0
\end{array}\right] \tag{1}</script><p>变换$f$的逆变换$f^{-1}$，$z=f^{-1}(x)=\left[\begin{matrix} \frac{1}{2}x_{2} \ x_{1}-\frac{1}{2}x_{2} \end{matrix}\right]$，$f^{-1}$的雅可比矩阵$J_{f^{-1}}$</p>
<script type="math/tex; mode=display">
J_{f^{-1}}=\left[\begin{array}{ccc}
\frac{\partial z_{1}}{\partial x_{1}} & \frac{\partial z_{1}}{\partial x_{2}} \\
\frac{\partial z_{2}}{\partial x_{1}} & \frac{\partial z_{2}}{\partial x_{2}}
\end{array}\right]
=\left[\begin{array}{ccc}
0 & \frac{1}{2} \\
1 & -\frac{1}{2}
\end{array}\right] \tag{2}</script><p>可以发现$J_{f}$与$J_{f^{-1}}$互为逆矩阵，事实上互为逆变换的$f$与$f^{-1}$，其二者对应的雅可比矩阵也互为逆阵，因此又由行列式的性质可得它们的雅可比行列式互为倒数，即</p>
<script type="math/tex; mode=display">
\lvert \mathbf{det} J_{f} \rvert = \lvert \mathbf{det} J_{f^{-1}} \rvert^{-1} \tag{3}</script><p>变换$f$可以不仅仅是矩阵变换，也可以任意的函数，将D维的向量$z$变换为D’维的$x$，$f: \mathbb{R}^{D} \rightarrow \mathbb{R}^{D’}$。</p>
<h2 id="1-3-Change-of-Variable-Theorem"><a href="#1-3-Change-of-Variable-Theorem" class="headerlink" title="1.3 Change of Variable Theorem"></a>1.3 Change of Variable Theorem</h2><p>假设有一变量$\mathbf{u}$，服从分布$\mathbf{u} \sim p_{u}(\mathbf{u})$，有一变换$T$，$\mathbf{x}=T(\mathbf{u})$，$p_{u}(\mathbf{u})$是已知的一种简单分布，变换$T$可逆，且$T$与$T^{-1}$都可微分，现在要求$p_{x}(\mathbf{x})$，即随机变量$\mathbf{x}$的概率密度函数，因为概率之和相等</p>
<script type="math/tex; mode=display">
\int_{x} p_{x}\left(\mathbf{x}\right) d \mathbf{x}=1=\int_{z} p_{z}\left(\mathbf{z}\right) d \mathbf{z} \tag{4}</script><p>因为x与u一一对应，所以从du体积映射到dx体积时，体积内包含的概率之和不变，那么被积分的部分绝对值必定处处相等，由于概率p必大于等于0，可去掉其两边的绝对值号，即得</p>
<script type="math/tex; mode=display">
\begin{eqnarray}
\left| p_{x}\left(\mathbf{x}\right) d \mathbf{x} \right| &=& \left| p_{z}\left(\mathbf{z}\right) d \mathbf{z} \right| \tag{5} \\ 
p_{x}\left(\mathbf{x}\right)  &=& p_{z}\left(\mathbf{z}\right) \left| \frac{d \mathbf{z}}{d \mathbf{x}} \right| \tag{6}\\
p_{x}\left(\mathbf{x}\right)  &=& p_{z}\left(\mathbf{z}\right) \left| \frac {\partial T^{-1}(\mathbf{x})}{\partial \mathbf{x}} \right| \tag{7}\\
p_{x}\left(\mathbf{x}\right)  &=& p_{z}\left(T^{-1}{(\mathbf{x})}\right) \left| \mathbf{det} J_{T^{-1}}(\mathbf{x}) \right| \tag{8}
\end{eqnarray}</script><p>第(8)式也可写为</p>
<script type="math/tex; mode=display">
p_{x}\left(\mathbf{x}\right) = p_{z}\left(\mathbf{z}\right) \tag{9} \left| \mathbf{det} J_{T}(\mathbf{z}) \right|^{-1}</script><p>(5)~(8)式的直观理解：两边都是概率密度乘以空间的大小，得到是一个标量，即随机变量落在该空间的概率大小，将变换$T$写入$\left| \frac{d \mathbf{z}}{d \mathbf{x}} \right|$，即将其写为$\left| \frac {\partial T^{-1}(\mathbf{x})}{\partial \mathbf{x}} \right|$，但x为向量而非标量，这里$\left| \frac{d \mathbf{z}}{d \mathbf{x}} \right|$要表示的是空间变化的大小关系，我们由雅可比矩阵的定义可知$\frac {\partial T^{-1}(\mathbf{x})}{\partial \mathbf{x}} = J_{T^{-1}}(\mathbf{x})$，又由行列式的物理意义，知道$J_{T}(\mathbf{z})$的绝对值为$T$将z映射到x时，空间大小放缩的倍数，即为概率密度放缩的倍数倒数，又因$\mathbf{det}J_{T^{-1}}(\mathbf{x}) = \mathbf{det}J_{T}(\mathbf{z})^{-1}$，因此可得(8)式。</p>
<p>论文原文的解释大意是：<strong><em>我们可以认为T在通过expand或contract R^D空间来使得pz变得和px相近。雅可比行列式detT的绝对值量化了原向量z附近的体积由于经过T变换后，体积相对变化的大小，即当z附近一块无穷小的体积dz，经过T后被map到了x附近的一块无穷小的体积dx处，那么detT等于dx除以dz，即映射后的体积是原来的几倍，因为dz中包含的概率等于dx中包含的概率，因此如果dz的体积被放大了，那么dx里的概率密度应该缩小</em></strong></p>
<p>举个例子，假设随机变量z属于0-1均匀分布，在取值空间$C_{1}$=(0, 1)上，p(z)=1，有变换T，T(z)=2z，令x=T(z)，则x必是$C_{2}$=(0, 2)上的均匀分布，但此时p(x)不再是1了，否则在(0, 2)上都有p(x)=1，积分可得概率之和为2，明显错误，因为变换T将原空间中z可取值的范围放大了一倍，从(0, 1)变为了(0, 2)，即可取值空间从$C_{1}$变为$C_{2}$，空间放大的倍数为$\left| \mathbf{det} J_{T}(\mathbf{z}) \right|=2$，那概率密度缩小的倍数为$\left| \mathbf{det} J_{T^{-1}}(\mathbf{x}) \right| = \frac{1}{2}$，即相应的x概率密度应该缩小一倍，因此</p>
<script type="math/tex; mode=display">
0.5 = p_{x}\left(\mathbf{x}\right)  = p_{z}\left(\mathbf{z}\right) \cdot \left| \mathbf{det} J_{T^{-1}}(\mathbf{x}) \right|  = 1 \cdot \frac{1}{2} \tag{10}</script><h1 id="2-标准化流的定义和基础"><a href="#2-标准化流的定义和基础" class="headerlink" title="2. 标准化流的定义和基础"></a>2. 标准化流的定义和基础</h1><p>我们的目标是使用简单的概率分布来建立我们想要的更为复杂更有表达能力的概率分布，使用的方法就是Normalizing Flow，flow的字面意思是一长串的T，即很多的transformation。让简单的概率分布，通过这一系列的transformation，一步一步变成complex、expressive的概率分布，like a fluid flowing through a set of tubes，fluid就是说概率分布像水一样，是可塑的易变形的，我们把它通过一系列tubes，即变换T们，塑造成我们想要的样子——最终的概率分布。下面开始使用的符号尽量与原论文保持一致。</p>
<h2 id="2-1-Normalizing-Flow’s-properties"><a href="#2-1-Normalizing-Flow’s-properties" class="headerlink" title="2.1 Normalizing Flow’s properties"></a>2.1 Normalizing Flow’s properties</h2><ol>
<li><p>x与u必须维度相同，因为只有维度相同，下面的变换T才可能可逆</p>
</li>
<li><p>变换T必须可逆，且T和T的逆必须可导</p>
</li>
<li><p>变换T可以由多个符合条件2的变换Ti组合而成</p>
<script type="math/tex; mode=display">
\begin{aligned}
\left(T_{2} \circ T_{1}\right)^{-1} &=T_{1}^{-1} \circ T_{2}^{-1} \\
\operatorname{det} J_{T_{2} \circ T_{1}}(\mathbf{u}) &=\operatorname{det} J_{T_{2}}\left(T_{1}(\mathbf{u})\right) \cdot \operatorname{det} J_{T_{1}}(\mathbf{u})
\end{aligned}</script></li>
</ol>
<p>从使用角度来说，一个flow-based model提供了两个操作，一是sampling，即从pu中sample出u，经过变换T得到x，$\mathbf{x}=T(\mathbf{u}) ~~where ~~\mathbf{u}\sim p_{u}(\mathbf{u})$，另一个是evaluating模型的概率分布，使用公式 $p_{\mathrm{x}}(\mathbf{x})=p_{\mathrm{u}}\left(T^{-1}(\mathbf{x})\right)\left|\operatorname{det} J_{T^{-1}}(\mathbf{x})\right|$。</p>
<p>两种操作有不同的计算要求，sampling需要能够sample from pu 以及计算变换T，evaluating需要能够计算T的逆与雅可比行列式，并evaluate pu，因此计算时的效率与难度对应用来说至关重要</p>
<h2 id="2-2-Flow-based-models有多强的表达能力？"><a href="#2-2-Flow-based-models有多强的表达能力？" class="headerlink" title="2.2 Flow-based models有多强的表达能力？"></a>2.2 Flow-based models有多强的表达能力？</h2><p>我们知道p(u)是很简单的一个概率分布，那么通过flow，我们能将p(u)转换为任意的概率分布p(x)吗？假设x为D维向量，p(x)&gt;0，$x_{i}$的概率分布只依赖i之前的元素$x_{&lt;i}$，那么可以将$p_{x}(x)$分解为条件概率的乘积</p>
<script type="math/tex; mode=display">
p_{\mathrm{x}}(\mathbf{x})=\prod_{i=1}^{D} p_{\mathrm{x}}\left(\mathrm{x}_{i} \mid \mathbf{x}_{<i}\right)</script><p>假设变换F将x映射为z，zi的值由xi的累积分布函数(cdf)确定</p>
<script type="math/tex; mode=display">
\mathrm{z}_{i}=F_{i}\left(\mathrm{x}_{i}, \mathbf{x}_{<i}\right)=\int_{-\infty}^{\mathrm{x}_{i}} p_{\mathrm{x}}\left(\mathrm{x}_{i}^{\prime} \mid \mathbf{x}_{<i}\right) d \mathrm{x}_{i}^{\prime}=\operatorname{Pr}\left(\mathrm{x}_{i}^{\prime} \leq \mathrm{x}_{i} \mid \mathbf{x}_{<i}\right)</script><p>很明显F是可微分的，其微分就等于$p_{x}(\mathbf{x}_{i}|\mathbf{x}_{<i})$，由于Fi对xj的偏微分当j > i时等于0，因此$J_{F}(\mathbf{x})$是一个下三角矩阵，那么其行列式就等于其对角线元素的乘积，即</p>
<script type="math/tex; mode=display">
\operatorname{det} J_{F}(\mathbf{x})=\prod_{i=1}^{D} \frac{\partial F_{i}}{\partial \mathrm{x}_{i}}=\prod_{i=1}^{D} p_{\mathrm{x}}\left(\mathrm{x}_{i} \mid \mathbf{x}_{<i}\right)=p_{\mathrm{x}}(\mathbf{x})>0</script><p>由于p(x)&gt;0，所以雅可比行列式也&gt;0，那么变换F的逆必存在，由(9)式，将x与z对调，T改为F，可得</p>
<script type="math/tex; mode=display">
p_{z}\left(\mathbf{z}\right) = p_{x}\left(\mathbf{x}\right) \left| \mathbf{det} J_{F}(\mathbf{x}) \right|^{-1} = 1</script><p>即z是D维空间中(0, 1)之间的均匀分布。</p>
<p>上述对p(x)的限制仅仅是$x_{i}$依赖于$x_{<i}$的条件概率对$(x_{i}, x_{<i})$可微，且$p_{x}(\mathbf{x})>0  ~\forall~\mathbf{x}\in \mathbb{R}^{D}$，我们就使用变换F将它变为了最简单的(0, 1)均匀分布，又因为F可逆，所以我们可以使用F的逆将p(z)转换为任意满足上述条件的概率分布p(x)。我们再推广到任意的base distribution，假设p(u)满足上述p(x)满足的条件，那么我们可以使用变换G将任意的概率分布p(u)转换为p(z)，再用F逆将p(z)转换为任意的概率分布p(x)，即 使用变换$T = F^{-1} \circ G$，可将$p_u{\mathbf{u}}$变为$p_{x}(\mathbf{x})$。</p>
<h2 id="2-3-使用flows来建模和推断"><a href="#2-3-使用flows来建模和推断" class="headerlink" title="2.3 使用flows来建模和推断"></a>2.3 使用flows来建模和推断</h2><p>为了拟合一个概率模型，我们要拟合一个flow-based model $p_{x}(\mathbf{x};\theta)$去近似目标分布$p_{x}^{*}(\mathbf{x})$，$\theta$代表$(\phi,\psi)$ ，$\phi$和$\psi$分别是T与p(u)的参数，可以通过最小化KL散度和最大似然估计做到</p>
<h3 id="2-3-1-正向KL散度与最大似然估计"><a href="#2-3-1-正向KL散度与最大似然估计" class="headerlink" title="2.3.1 正向KL散度与最大似然估计"></a>2.3.1 正向KL散度与最大似然估计</h3><script type="math/tex; mode=display">
\begin{aligned}
\mathcal{L}(\boldsymbol{\theta}) &=D_{\mathrm{KL}}\left[p_{\mathrm{x}}^{*}(\mathbf{x}) \| p_{\mathrm{x}}(\mathbf{x} ; \boldsymbol{\theta})\right] \\
&=-\mathbb{E}_{p_{\mathrm{x}}^{*}(\mathbf{x})}\left[\log p_{\mathrm{x}}(\mathbf{x} ; \boldsymbol{\theta})\right]+\mathrm{const.} \\
&=-\mathbb{E}_{p_{\mathrm{x}}^{*}(\mathbf{x})}\left[\log p_{\mathrm{u}}\left(T^{-1}(\mathbf{x} ; \boldsymbol{\phi}) ; \boldsymbol{\psi}\right)+\log \left|\operatorname{det} J_{T^{-1}}(\mathbf{x} ; \boldsymbol{\phi})\right|\right]+\mathrm{const.}
\end{aligned}</script><p>假设现在我们手上有N条真实的数据，即来自于$p_{x}^{*}(\mathbf{x})$的samples，那么可以使用蒙特卡罗法来近似上面的期望值</p>
<script type="math/tex; mode=display">
\mathcal{L}(\boldsymbol{\theta}) \approx-\frac{1}{N} \sum_{n=1}^{N} \log p_{\mathrm{u}}\left(T^{-1}\left(\mathbf{x}_{n} ; \boldsymbol{\phi}\right) ; \boldsymbol{\psi}\right)+\log \left|\operatorname{det} J_{T^{-1}}\left(\mathbf{x}_{n} ; \boldsymbol{\phi}\right)\right|+\text { const. }</script><p>最小化上式等价于求模型在该N条数据上的最大似然估计，我们一般使用随机梯度下降来优化上式的参数。</p>
<p>可见，为了使用正向KL散度或最大似然估计来拟合目标分布，我们需要计算$T^{-1}$、它的雅可比行列式， evaluate base分布 $p_{u}(\mathbf{u};\psi)$，以及关于它们参数的导数。</p>
<h3 id="2-3-2-反向KL散度"><a href="#2-3-2-反向KL散度" class="headerlink" title="2.3.2 反向KL散度"></a>2.3.2 反向KL散度</h3><script type="math/tex; mode=display">
\begin{aligned}
\mathcal{L}(\boldsymbol{\theta}) &=D_{\mathrm{KL}}\left[p_{\mathrm{x}}(\mathbf{x} ; \boldsymbol{\theta}) \| p_{\mathrm{x}}^{*}(\mathbf{x})\right] \\
&=\mathbb{E}_{p_{\mathrm{x}}(\mathbf{x} ; \boldsymbol{\theta})}\left[\log p_{\mathrm{x}}(\mathbf{x} ; \boldsymbol{\theta})-\log p_{\mathrm{x}}^{*}(\mathbf{x})\right] \\
&=\mathbb{E}_{p_{\mathrm{u}}(\mathbf{u} ; \boldsymbol{\psi})}\left[\log p_{\mathrm{u}}(\mathbf{u} ; \boldsymbol{\psi})-\log \left|\operatorname{det} J_{T}(\mathbf{u} ; \boldsymbol{\phi})\right|-\log p_{\mathrm{x}}^{*}(T(\mathbf{u} ; \boldsymbol{\phi}))\right]
\end{aligned}</script><p>当我们能够计算T，它的雅可比行列式，evaluate 目标分布p*以及从p(u)中sample时，使用反向KL散度是合适的，事实上，即使我们只能evaluate 目标分布乘以某个正则化常数，也可以最小化上式，$p_{\mathrm{x}}^{*}(\mathbf{x})=\widetilde{p}_{\mathrm{x}}(\mathbf{x}) / C$，$\widetilde{p}_{\mathrm{x}}(\mathbf{x})$是一个更好处理的概率分布，重写上式为</p>
<script type="math/tex; mode=display">
\mathcal{L}(\boldsymbol{\theta})=\mathbb{E}_{p_{\mathrm{u}}(\mathbf{u} ; \boldsymbol{\psi})}\left[\log p_{\mathrm{u}}(\mathbf{u} ; \boldsymbol{\psi})-\log \left|\operatorname{det} J_{T}(\mathbf{u} ; \boldsymbol{\phi})\right|-\log \widetilde{p}_{\mathrm{x}}(T(\mathbf{u} ; \boldsymbol{\phi}))\right]+\text { const. }</script><p>当我们有N条来自于$p_{u}(\mathbf{u;\psi})$的samples，为了最小化上式，使用蒙特卡罗法，并对变换T的参数$\phi$求偏导，可得</p>
<script type="math/tex; mode=display">
\nabla_{\phi} \mathcal{L}(\boldsymbol{\theta}) \approx-\frac{1}{N} \sum_{n=1}^{N} \nabla_{\boldsymbol{\phi}} \log \left|\operatorname{det} J_{T}\left(\mathbf{u}_{n} ; \boldsymbol{\phi}\right)\right|+\nabla_{\boldsymbol{\phi}} \log \widetilde{p}_{\mathbf{x}}\left(T\left(\mathbf{u}_{n} ; \boldsymbol{\phi}\right)\right)</script><p>如何构建Normalizing flow将在中篇和下篇介绍</p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/07/23/CS224n-lecture10-Question-Answering/" rel="next" title="CS224n-lecture10-Question Answering">
                <i class="fa fa-chevron-left"></i> CS224n-lecture10-Question Answering
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/07/30/%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%81%E7%AC%94%E8%AE%B0/" rel="prev" title="《Normalizing Flows for Probabilistic Modeling and Inference》论文笔记">
                《Normalizing Flows for Probabilistic Modeling and Inference》论文笔记 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/header.jpg"
                alt="TianHongZXY"/>
            
              <p class="site-author-name" itemprop="name">TianHongZXY</p>
              <p class="site-description motion-element" itemprop="description">浪漫骑士 行吟诗人 自由思想者</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/%20%7C%7C%20archive">
                
                    <span class="site-state-item-count">27</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">6</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">8</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/TianHongZXY" title="GitHub &rarr; https://github.com/TianHongZXY" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="/mailto:tianhongzxy@163.com" title="E-Mail &rarr; mailto:tianhongzxy@163.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://www.zhihu.com/people/tian-qian-bu-dang-hong-zhi" title="知乎 &rarr; https://www.zhihu.com/people/tian-qian-bu-dang-hong-zhi" rel="noopener" target="_blank"><i class="fa fa-fw fa-globe"></i>知乎</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#《Normalizing-Flows-for-Probabilistic-Modeling-and-Inference》论文笔记"><span class="nav-number">1.</span> <span class="nav-text">《Normalizing Flows for Probabilistic Modeling and Inference》论文笔记</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-前置知识"><span class="nav-number">2.</span> <span class="nav-text">1. 前置知识</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-行列式"><span class="nav-number">2.1.</span> <span class="nav-text">1.1 行列式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-雅可比矩阵"><span class="nav-number">2.2.</span> <span class="nav-text">1.2 雅可比矩阵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-Change-of-Variable-Theorem"><span class="nav-number">2.3.</span> <span class="nav-text">1.3 Change of Variable Theorem</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-标准化流的定义和基础"><span class="nav-number">3.</span> <span class="nav-text">2. 标准化流的定义和基础</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-Normalizing-Flow’s-properties"><span class="nav-number">3.1.</span> <span class="nav-text">2.1 Normalizing Flow’s properties</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-Flow-based-models有多强的表达能力？"><span class="nav-number">3.2.</span> <span class="nav-text">2.2 Flow-based models有多强的表达能力？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-使用flows来建模和推断"><span class="nav-number">3.3.</span> <span class="nav-text">2.3 使用flows来建模和推断</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-1-正向KL散度与最大似然估计"><span class="nav-number">3.3.1.</span> <span class="nav-text">2.3.1 正向KL散度与最大似然估计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-2-反向KL散度"><span class="nav-number">3.3.2.</span> <span class="nav-text">2.3.2 反向KL散度</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2019 – <span itemprop="copyrightYear">2020</span>
  <!-- <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span> -->
  <span class="author" itemprop="copyrightHolder"><span class="with-love"><i class="fa fa-heart-o"></i></span>TianHongZXY</span>

  

  
</div>
<!--

  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.0.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v6.7.0</div>

-->


        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=6.7.0"></script>

  <script src="/js/src/motion.js?v=6.7.0"></script>



  
  

  
  <script src="/js/src/scrollspy.js?v=6.7.0"></script>
<script src="/js/src/post-details.js?v=6.7.0"></script>



  


  <script src="/js/src/bootstrap.js?v=6.7.0"></script>



  



  








  
  
  
  
  <script src="//cdn1.lncld.net/static/js/3.11.1/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  <script>
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(function (item) {
      return GUEST.indexOf(item) > -1;
    });
    new Valine({
      el: '#comments' ,
      verify: false,
      notify: false,
      appId: 'fNjvG519rNMQCRTez4XP1aGe-gzGzoHsz',
      appKey: 'DY0fa7oCKanbyW5J4UoxG9ug',
      placeholder: 'Say something',
      avatar: 'mm',
      meta:guest,
      pageSize: '10' || 10,
      visitor: false
    });
  </script>




  





  

  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: "AMS"
      }
    }
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
      for (i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
  overflow: auto hidden;
}
</style>

    
  


  
  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>
  <script>
    
    
  </script>


  

  

  

  

  

  

  

  
  <!-- 页面点击小红心 -->
  <script type="text/javascript" src="/js/src/click.js"></script>
</body>
</html>
